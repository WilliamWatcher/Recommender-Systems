{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "from datetime import datetime as datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all impressions for a user and add them to a df\n",
    "def get_impressions(userID, behavior_view):\n",
    "    test = []\n",
    "    for index, row in behavior_view.iterrows():\n",
    "        if row[\"User ID\"] == userID:\n",
    "            for impression in row[\"Impressions\"].split(\" \"):\n",
    "                imp = impression.split(\"-\")\n",
    "                if imp[1] == \"1\":\n",
    "                    test.append((imp[0], 1))\n",
    "                else:\n",
    "                    test.append((imp[0], 0))\n",
    "    return pd.DataFrame(test, columns=[\"News ID\", \"Response\"])\n",
    "\n",
    "\n",
    "# Join response to our predictions in order to sort them before evaluation\n",
    "def create_evaluation_data(scored_data, userID):\n",
    "    return scored_data.join(get_impressions(userID).set_index(\"News ID\"), how=\"inner\", on=\"News ID\")\n",
    "\n",
    "\n",
    "# Get df of all user IDs\n",
    "def get_users(view1, view2):\n",
    "    return pd.merge(left=view1[\"User ID\"], right=view2[\"User ID\"], how=\"inner\", on=\"User ID\")[\"User ID\"].unique()\n",
    "\n",
    "#userList = __get_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_view(behavior, t0, t1):\n",
    "    df = behavior[(behavior[\"Timestamp\"] >= t0) & (behavior[\"Timestamp\"] < t1)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = pd.read_csv(\"data/MINDsmall_train/behaviors.tsv\", sep=\"\\t\", header=None, names=[\"Impression ID\", \"User ID\", \"Time\", \"History\", \"Impressions\"])\n",
    "news = pd.read_csv(\"data/MINDsmall_train/news.tsv\", sep=\"\\t\", header=None, names=[\"News ID\", \"Category\", \"Subcategory\", \"Title\", \"Abstract\", \"URL\", \"Title Entities\", \"Abstract Entities\", \"Title Topics\", \"Abstract Topics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Impression ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>History</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103760</th>\n",
       "      <td>103761</td>\n",
       "      <td>U68089</td>\n",
       "      <td>11/9/2019 1:00:03 PM</td>\n",
       "      <td>N138 N29177 N28850 N22745 N55326 N53100 N33969...</td>\n",
       "      <td>N52000-0 N41881-0 N60374-0 N5442-0 N51398-0 N5...</td>\n",
       "      <td>1.573258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42450</th>\n",
       "      <td>42451</td>\n",
       "      <td>U56509</td>\n",
       "      <td>11/9/2019 1:00:17 PM</td>\n",
       "      <td>N51214 N60979 N9293 N4786 N13380 N14149 N2155</td>\n",
       "      <td>N63685-0 N34799-0 N26130-0 N51378-0 N7891-0 N6...</td>\n",
       "      <td>1.573258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116953</th>\n",
       "      <td>116954</td>\n",
       "      <td>U34617</td>\n",
       "      <td>11/9/2019 1:00:22 PM</td>\n",
       "      <td>N11863 N44310 N31064</td>\n",
       "      <td>N52000-0 N41881-0 N27845-1 N47020-0 N51398-0</td>\n",
       "      <td>1.573258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26087</th>\n",
       "      <td>26088</td>\n",
       "      <td>U11984</td>\n",
       "      <td>11/9/2019 1:00:33 PM</td>\n",
       "      <td>N39074 N3501 N31457 N61864 N3493 N25971 N29718...</td>\n",
       "      <td>N47020-1 N27845-0 N41881-0 N51398-0 N52000-0</td>\n",
       "      <td>1.573258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>14465</td>\n",
       "      <td>U74966</td>\n",
       "      <td>11/9/2019 1:00:39 PM</td>\n",
       "      <td>N39074 N19760 N20530 N58668 N44495 N20039 N339...</td>\n",
       "      <td>N59852-0 N47020-0 N39115-0 N58051-0 N37088-0 N...</td>\n",
       "      <td>1.573258e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95717</th>\n",
       "      <td>95718</td>\n",
       "      <td>U6300</td>\n",
       "      <td>11/14/2019 12:59:46 PM</td>\n",
       "      <td>N28296 N34087 N37942 N27311 N35022 N42620</td>\n",
       "      <td>N50872-0 N25165-0 N29212-0 N32567-0 N16439-0 N...</td>\n",
       "      <td>1.573733e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140318</th>\n",
       "      <td>140319</td>\n",
       "      <td>U15094</td>\n",
       "      <td>11/14/2019 12:59:47 PM</td>\n",
       "      <td>N33038 N19494 N54377 N21242 N29499 N55743 N330...</td>\n",
       "      <td>N56142-0 N23446-0 N19661-1 N18529-0 N41387-0 N...</td>\n",
       "      <td>1.573733e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107052</th>\n",
       "      <td>107053</td>\n",
       "      <td>U80707</td>\n",
       "      <td>11/14/2019 12:59:50 PM</td>\n",
       "      <td>N33358 N8887 N55922 N23554 N30578 N48904 N4595...</td>\n",
       "      <td>N23446-0 N50872-0 N1952-0 N45523-0 N38779-0 N3...</td>\n",
       "      <td>1.573733e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124875</th>\n",
       "      <td>124876</td>\n",
       "      <td>U43003</td>\n",
       "      <td>11/14/2019 12:59:55 PM</td>\n",
       "      <td>N13427 N16158 N16233 N42526 N7422 N9226 N55743...</td>\n",
       "      <td>N63060-0 N38779-0 N10960-0 N1539-0 N9284-0 N34...</td>\n",
       "      <td>1.573733e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142843</th>\n",
       "      <td>142844</td>\n",
       "      <td>U83552</td>\n",
       "      <td>11/14/2019 12:59:58 PM</td>\n",
       "      <td>N6233 N64661 N51238 N58090 N4285 N39677 N30353...</td>\n",
       "      <td>N1539-0 N19661-0 N20270-0 N38779-1 N34185-0 N6...</td>\n",
       "      <td>1.573733e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156965 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Impression ID User ID                    Time  \\\n",
       "103760         103761  U68089    11/9/2019 1:00:03 PM   \n",
       "42450           42451  U56509    11/9/2019 1:00:17 PM   \n",
       "116953         116954  U34617    11/9/2019 1:00:22 PM   \n",
       "26087           26088  U11984    11/9/2019 1:00:33 PM   \n",
       "14464           14465  U74966    11/9/2019 1:00:39 PM   \n",
       "...               ...     ...                     ...   \n",
       "95717           95718   U6300  11/14/2019 12:59:46 PM   \n",
       "140318         140319  U15094  11/14/2019 12:59:47 PM   \n",
       "107052         107053  U80707  11/14/2019 12:59:50 PM   \n",
       "124875         124876  U43003  11/14/2019 12:59:55 PM   \n",
       "142843         142844  U83552  11/14/2019 12:59:58 PM   \n",
       "\n",
       "                                                  History  \\\n",
       "103760  N138 N29177 N28850 N22745 N55326 N53100 N33969...   \n",
       "42450       N51214 N60979 N9293 N4786 N13380 N14149 N2155   \n",
       "116953                               N11863 N44310 N31064   \n",
       "26087   N39074 N3501 N31457 N61864 N3493 N25971 N29718...   \n",
       "14464   N39074 N19760 N20530 N58668 N44495 N20039 N339...   \n",
       "...                                                   ...   \n",
       "95717           N28296 N34087 N37942 N27311 N35022 N42620   \n",
       "140318  N33038 N19494 N54377 N21242 N29499 N55743 N330...   \n",
       "107052  N33358 N8887 N55922 N23554 N30578 N48904 N4595...   \n",
       "124875  N13427 N16158 N16233 N42526 N7422 N9226 N55743...   \n",
       "142843  N6233 N64661 N51238 N58090 N4285 N39677 N30353...   \n",
       "\n",
       "                                              Impressions     Timestamp  \n",
       "103760  N52000-0 N41881-0 N60374-0 N5442-0 N51398-0 N5...  1.573258e+09  \n",
       "42450   N63685-0 N34799-0 N26130-0 N51378-0 N7891-0 N6...  1.573258e+09  \n",
       "116953       N52000-0 N41881-0 N27845-1 N47020-0 N51398-0  1.573258e+09  \n",
       "26087        N47020-1 N27845-0 N41881-0 N51398-0 N52000-0  1.573258e+09  \n",
       "14464   N59852-0 N47020-0 N39115-0 N58051-0 N37088-0 N...  1.573258e+09  \n",
       "...                                                   ...           ...  \n",
       "95717   N50872-0 N25165-0 N29212-0 N32567-0 N16439-0 N...  1.573733e+09  \n",
       "140318  N56142-0 N23446-0 N19661-1 N18529-0 N41387-0 N...  1.573733e+09  \n",
       "107052  N23446-0 N50872-0 N1952-0 N45523-0 N38779-0 N3...  1.573733e+09  \n",
       "124875  N63060-0 N38779-0 N10960-0 N1539-0 N9284-0 N34...  1.573733e+09  \n",
       "142843  N1539-0 N19661-0 N20270-0 N38779-1 N34185-0 N6...  1.573733e+09  \n",
       "\n",
       "[156965 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def str_to_timestamp(str):\n",
    "    return datetime.strptime(str, \"%m/%d/%Y %H:%M:%S %p\").timestamp()\n",
    "\n",
    "timestamps = behavior[\"Time\"].apply(str_to_timestamp)\n",
    "behavior[\"Timestamp\"] = timestamps\n",
    "behavior.sort_values(by=\"Timestamp\")\n",
    "# Add to new column instead of overwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Feature-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run feature_based.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving timeframe\n",
      "moving timeframe\n",
      "moving timeframe\n",
      "Predictions for user U85982 evaluated!\n",
      "Predictions for user U31142 evaluated!\n",
      "Predictions for user U9235 evaluated!\n",
      "Predictions for user U56223 evaluated!\n",
      "Predictions for user U23595 evaluated!\n",
      "Predictions for user U48683 evaluated!\n",
      "Predictions for user U66447 evaluated!\n",
      "Predictions for user U18291 evaluated!\n",
      "Predictions for user U24591 evaluated!\n",
      "Predictions for user U52342 evaluated!\n",
      "Predictions for user U83533 evaluated!\n",
      "Predictions for user U32479 evaluated!\n",
      "Predictions for user U11828 evaluated!\n",
      "Predictions for user U78924 evaluated!\n",
      "Predictions for user U40260 evaluated!\n",
      "Predictions for user U13061 evaluated!\n",
      "Predictions for user U90567 evaluated!\n",
      "Predictions for user U58141 evaluated!\n",
      "Predictions for user U58191 evaluated!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m users \u001b[38;5;241m=\u001b[39m get_users(test_view, train_view)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m users:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#x_i = create_user_vector(user, X_j, train_view)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     x_i \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_x_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_view\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m#prediction = pd.DataFrame(find_top_k_articles(user, X_j, 10, news_id_to_index), columns=[\"News ID\", \"Score\"])\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     response \u001b[38;5;241m=\u001b[39m get_impressions(user, test_view)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4636\\3671358685.py:39\u001b[0m, in \u001b[0;36mcreate_x_i\u001b[1;34m(userID, behavior)\u001b[0m\n\u001b[0;32m     36\u001b[0m history_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     37\u001b[0m article_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 39\u001b[0m category, subcategory \u001b[38;5;241m=\u001b[39m \u001b[43marticle_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticleID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m add_feature_to_xi(x_i, category, w_cat\u001b[38;5;241m*\u001b[39mw_history\u001b[38;5;241m/\u001b[39mhistory_count)\n\u001b[0;32m     41\u001b[0m add_feature_to_xi(x_i, subcategory, w_subcat\u001b[38;5;241m*\u001b[39mw_history\u001b[38;5;241m/\u001b[39mhistory_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4636\\3671358685.py:4\u001b[0m, in \u001b[0;36marticle_tags\u001b[1;34m(articleID)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marticle_tags\u001b[39m(articleID):\n\u001b[0;32m      3\u001b[0m     tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m     article \u001b[38;5;241m=\u001b[39m news\u001b[38;5;241m.\u001b[39mloc[\u001b[43mnews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNews ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marticleID\u001b[49m]\n\u001b[0;32m      5\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(article[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m     tags\u001b[38;5;241m.\u001b[39mappend(article[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\Documents\\School\\sem9\\RecSysProject\\Recommender-Systems\\local\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\Documents\\School\\sem9\\RecSysProject\\Recommender-Systems\\local\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\Documents\\School\\sem9\\RecSysProject\\Recommender-Systems\\local\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\Documents\\School\\sem9\\RecSysProject\\Recommender-Systems\\local\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\Documents\\School\\sem9\\RecSysProject\\Recommender-Systems\\local\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#X_j, news_id_to_index = create_all_item_vectors(news, behavior)\n",
    "X_j= create_all_x_j()\n",
    "\n",
    "evaluations_ndcg = []\n",
    "evaluations_pak = []\n",
    "t0 = float(behavior[\"Timestamp\"][0])\n",
    "tn = float(behavior[\"Timestamp\"][len(behavior[\"Timestamp\"])-1])\n",
    "split_ratio = 2/3\n",
    "dt = (tn-t0)/10\n",
    "k = 5\n",
    "\n",
    "while t0 <= tn-dt:\n",
    "    tsplit = t0 + dt*split_ratio\n",
    "    t1 = t0 + dt\n",
    "\n",
    "    train_view = get_view(behavior, t0, tsplit)\n",
    "    test_view = get_view(behavior, tsplit, t1)\n",
    "\n",
    "    users = get_users(test_view, train_view)\n",
    "\n",
    "    for user in users:\n",
    "        #x_i = create_user_vector(user, X_j, train_view)\n",
    "        #x_i = create_x_i(user, train_view)\n",
    "        prediction = pd.DataFrame(find_top_k_articles(user, X_j, 10, news_id_to_index), columns=[\"News ID\", \"Score\"])\n",
    "        response = get_impressions(user, test_view)\n",
    "        #prediction = pd.DataFrame(score(x_i, X_j, response[\"News ID\"]), columns=[\"News ID\", \"Score\"])\n",
    "        pred_resp = prediction.join(response.set_index(\"News ID\"), on=\"News ID\", how=\"inner\")\n",
    "        try:\n",
    "            evaluation = ndcg_score(np.array([pred_resp[\"Response\"].to_numpy()]), np.array([pred_resp[\"Score\"].to_numpy()]))\n",
    "            evaluations_ndcg.append(evaluation)\n",
    "            k_slice = pred_resp[\"Response\"].iloc[:k]\n",
    "            evaluation = k_slice.sum()/min(len(k_slice), k)\n",
    "            evaluations_pak.append(evaluation)\n",
    "            print(\"Predictions for user \" + user + \" evaluated!\")\n",
    "        except:\n",
    "            print(\"Eval failed\")\n",
    "            pass\n",
    "\n",
    "    print(\"moving timeframe\")\n",
    "    t0 = tsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nDCG:\")\n",
    "print(sum(evaluations_ndcg)/len(evaluations_ndcg))\n",
    "print(\"Precision at K:\")\n",
    "print(sum(evaluations_pak)/len(evaluations_pak))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run item_collab_filtering.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_ndcg = []\n",
    "evaluations_pak = []\n",
    "t0 = float(behavior[\"Timestamp\"][0])\n",
    "tn = float(behavior[\"Timestamp\"][len(behavior[\"Timestamp\"])-1])\n",
    "split_ratio = 2/3\n",
    "dt = (tn-t0)/10\n",
    "k = 5\n",
    "\n",
    "while t0 <= tn-dt:\n",
    "    tsplit = t0 + dt*split_ratio\n",
    "    t1 = t0 + dt\n",
    "\n",
    "    train_view = get_view(behavior, t0, tsplit)\n",
    "    test_view = get_view(behavior, tsplit, t1)\n",
    "\n",
    "    model = train_collaborative_filtering_model(train_view)\n",
    "    users = get_users(test_view, train_view)\n",
    "\n",
    "    for user in users:\n",
    "        prediction = get_top_n_recommendations(user, model, N=10).toPandas()\n",
    "        response = get_impressions(user, test_view)\n",
    "        pred_resp = prediction.join(response.set_index(\"News ID\"), on=\"news_id\", how=\"inner\")\n",
    "        try:\n",
    "            evaluation = ndcg_score(np.array([pred_resp[\"Response\"].to_numpy()]), np.array([pred_resp[\"Score\"].to_numpy()]))\n",
    "            evaluations_ndcg.append(evaluation)\n",
    "            k_slice = pred_resp[\"Response\"].iloc[:k]\n",
    "            evaluation = k_slice.sum()/min(len(k_slice), k)\n",
    "            evaluations_pak.append(evaluation)\n",
    "            print(\"Predictions for user \" + user + \" evaluated!\")\n",
    "        except:\n",
    "            print(\"Eval failed\")\n",
    "            pass\n",
    "\n",
    "    print(\"moving timeframe\")\n",
    "    t0 = tsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nDCG:\")\n",
    "print(sum(evaluations_ndcg)/len(evaluations_ndcg))\n",
    "print(\"Precision at K:\")\n",
    "print(sum(evaluations_pak)/len(evaluations_pak))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
